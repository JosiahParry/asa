{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Spatial Analysis\n",
    "# Module 09: Spatial weights and ESDA\n",
    "\n",
    "ESDA: Exploratory Spatial Data Analysis\n",
    "\n",
    "\"Everything is related to everything else, but near things are more related than distant things\" -Waldo Tobler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysal as ps\n",
    "import seaborn as sns\n",
    "from scipy.stats import stats\n",
    "\n",
    "np.random.seed(0)\n",
    "print(gpd.__version__, ps.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tracts data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gpd.read_file('census/census_tracts_data.geojson')\n",
    "tracts = tracts.set_index('index')\n",
    "tracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pop density in persons per sq km\n",
    "tracts['pop_density'] = tracts['total_pop'] / (tracts['ALAND'] / 1e6)\n",
    "tracts = tracts.replace([np.inf, -np.inf], np.nan)\n",
    "tracts = tracts.dropna(subset=['pop_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_ma = '+proj=utm +zone=18 +ellps=WGS84 +datum=WGS84 +units=m +no_defs'\n",
    "tracts = tracts.to_crs(utm_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_variable(df, col):\n",
    "    values = df.dropna(subset=[col])\n",
    "    ax = values.plot(column=col, scheme='quantiles', k=10, cmap='plasma', figsize=(10,10))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_variable(tracts, 'pop_density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_variable(tracts, 'med_household_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like these two variables might be negatively correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation coefficient and its p-value\n",
    "x = tracts.dropna(subset=['pop_density', 'med_household_income'])['pop_density']\n",
    "y = tracts.dropna(subset=['pop_density', 'med_household_income'])['med_household_income']\n",
    "r, p = stats.pearsonr(x=x, y=y)\n",
    "print('r={:.4f}, p={:.4f}'.format(r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot them\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=x, y=y, s=1)\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate a simple linear regression model\n",
    "m, b, r, p, se = stats.linregress(x=x, y=y)\n",
    "print('m={:.4f}, b={:.4f}, r^2={:.4f}, p={:.4f}'.format(m, b, r ** 2, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the regression line with 95% CI\n",
    "ax = sns.regplot(x, y, marker='.', scatter_kws={'s':2})\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spatial weights matrix\n",
    "\n",
    "Spatial weights define the spatial connections among our units of analysis (tracts).\n",
    "\n",
    "### 2.1. Contiguity-based weights: rook contiguity\n",
    "\n",
    "Using rook contiguity, two spatial units must share an edge of their boundaries to be considered neighbors. This isn't terribly common in practice (since queen is more useful, but it's worth understanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tract labels (GEOIDs) and pick one to work with later\n",
    "labels = tracts.index.tolist()\n",
    "label = labels[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_rook = ps.lib.weights.Rook.from_dataframe(tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Contiguity-based weights: queen contiguity\n",
    "\n",
    "Using queen contiguity, two spatial units need only share a vertex (a single point) of their boundaries to be considered neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_queen = ps.lib.weights.Queen.from_dataframe(tracts, ids=labels, id_order=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the neighbors of some tract\n",
    "w_queen.neighbors[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a raw contiguity matrix, so weights are all 1\n",
    "w_queen.weights[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many neighbors does this tract have?\n",
    "w_queen.cardinalities[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cardinalites to series and describe data -- looks right-skewed\n",
    "cardinalites_queen = pd.Series(w_queen.cardinalities)\n",
    "cardinalites_queen.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cardinalites_queen.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations\n",
    "w_queen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of neighbors\n",
    "w_queen.mean_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min number of neighbors\n",
    "w_queen.min_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max number of neighbors\n",
    "w_queen.max_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# islands (observations with no neighbors, disconnected in space)\n",
    "w_queen.islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "tracts.plot(ax=ax, facecolor='#999999', edgecolor='w', linewidth=0.5)\n",
    "\n",
    "# plot some tract of interest in red\n",
    "tract = tracts.loc[[label]]\n",
    "tract.plot(ax=ax, facecolor='r', edgecolor='w', linewidth=1)\n",
    "\n",
    "# plot the neighbors in blue\n",
    "neighbors = tracts.loc[w_queen[label]]\n",
    "neighbors.plot(ax=ax, facecolor='b', edgecolor='w', linewidth=1)\n",
    "\n",
    "# zoom to area of interest\n",
    "xmin, ymin, xmax, ymax = neighbors.unary_union.bounds\n",
    "ax.axis('equal')\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "ax.set_title('Neighbors of tract {}'.format(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# draw a contiguity graph of the tracts\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "tracts.plot(ax=ax, facecolor='#333333', edgecolor='w', linewidth=0.2)\n",
    "\n",
    "for label, neighbors in w_queen:\n",
    "    focal = np.hstack(tracts.loc[label, 'geometry'].centroid.xy)\n",
    "    centroids = np.vstack(tracts.loc[neighbors, 'geometry'].apply(lambda g: (g.centroid.x, g.centroid.y)).values)\n",
    "    for neighbor in centroids:\n",
    "        ax.plot(*zip(focal, neighbor), color='r', linewidth=0.3)\n",
    "\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Distance-based weights: k-nn\n",
    "\n",
    "Find the k-nearest neighbors of each tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbors finds the closest k tract centroids to each tract centroid\n",
    "# here, k=6\n",
    "w_knn = ps.lib.weights.KNN.from_dataframe(tracts, k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Distance-based weights: distance band\n",
    "\n",
    "Tracts are considered neighbors of some tract if they are within some threshold distance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tracts.centroid.x\n",
    "y = tracts.centroid.y\n",
    "coords = np.array([x, y]).T\n",
    "threshold = ps.lib.weights.min_threshold_distance(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_dist = ps.lib.weights.distance.DistanceBand.from_dataframe(tracts, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w_dist.neighbors[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Standardizing weights\n",
    "\n",
    "A spatial weights matrix with raw values (e.g. 1s and 0s for neighbor/not) is not always the best for analysis. Some sort of standardization is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current transformation of the weights matrix (O = original)\n",
    "w_queen.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we want to apply a row-based transformation, so every row of the matrix sums up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.transform = 'R'\n",
    "w_queen[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySAL supports the following transformations:\n",
    "\n",
    "  - O: original, returning the object to the initial state\n",
    "  - B: binary, with every neighbor having assigned a weight of 1\n",
    "  - R: row-based, with all the neighbors of a given observation adding up to 1\n",
    "  - V: variance stabilizing, with the sum of all the weights being constrained to the number of observations\n",
    "\n",
    "**It can take a long time to calculate a weights matrix for a large data set.**\n",
    "\n",
    "Once you've created yours, you might want to save it to disk to re-use in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your matrix to disk\n",
    "f = ps.lib.io.open('tracts_queen.gal', 'w')\n",
    "f.write(w_queen)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a matrix from disk (notice its transformation)\n",
    "w_queen = ps.lib.io.open('tracts_queen.gal', 'r').read()\n",
    "w_queen[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial lag\n",
    "\n",
    "Using the `med_household_income` variable. If the spatial weights matrix is row-standardized, then the spatial lag is the average value of an observation's neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'med_household_income'\n",
    "tracts_not_null = tracts[[col, 'geometry']].dropna()\n",
    "y = tracts_not_null[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen = ps.lib.weights.Queen.from_dataframe(tracts_not_null)\n",
    "w_queen.transform = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute spatial lag\n",
    "y_lag = ps.lib.weights.lag_spatial(w_queen, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_lag = '{}_lag'.format(col)\n",
    "data_lag = pd.DataFrame(data={col:y, col_lag:y_lag}).astype(int)\n",
    "data_lag.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Spatial autocorrelation\n",
    "\n",
    "Statistical models typically assume that the observations are independent of each other. This assumption is violated when a variable's value at one location is correlated with its value at nearby locations. This is called spatial autocorrelation, and is common in the real world due to proximity-based spillover effects. Substantive spatial autocorrelation can be explained by social or economic theory that describes a spatial relationship. Nuisance spatial autocorrelation stems from data problems.\n",
    "\n",
    "*Positive spatial autocorrelation*: nearby values tend to be more similar (e.g. income, home values, temperature, rainfall)\n",
    "\n",
    "*Negative spatial autocorrelation*: nearby values tend to be more dissimilar (e.g. fire stations, grocery stores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Moran's I\n",
    "\n",
    "Moran's I measures *global* spatial autocorrelation: do values tend to be near other (dis)similar values. Values > 1 indicate positive spatial autocorrelation, and values < 1 indicate negative spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the statistic\n",
    "mi = ps.explore.esda.Moran(data_lag[col], w_queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the I value\n",
    "mi.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical inference: show the p value\n",
    "mi.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we generated a large number of maps with the same values but randomly allocated over space, and calculated Moran's I for each of these maps, only 0.1% of them would display a larger absolute value than the one we computed from the real-world data set. Thus there is a 0.1% chance of getting the observed value of Moran's I if the spatial distribution of our variable is random. We can conclude that the variable's distribution is statistically-significantly postively spatially autocorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Moran plots\n",
    "\n",
    "A Moran plot scatter plots the spatially-lagged values (y-axis) vs the original variable's values (x-axis). Moran's I is the slope of the line in a Moran plot, which makes this a bit easier to conceptualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.regplot(x=col, y=col_lag, data=data_lag, scatter_kws={'s':1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the vector (i.e., calculate z-scores)\n",
    "y_std = (y - y.mean()) / y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the spatial lag of the standardized vector and save it as a series indexed like the original vector\n",
    "y_std_lag = pd.Series(ps.lib.weights.lag_spatial(w_queen, y_std), index=y_std.index, name=col_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized moran's plot, ignoring outliers beyond 3 std devs\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "sns.regplot(ax=ax, x=y_std, y=y_std_lag, scatter_kws={'s':1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the 95% confidence interval shading and the positive slope. Given the value of Moran's I that we calculated earlier (and its p-value), we can conclude that the slope of the line is statistically-significantly different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate a simple linear regression model\n",
    "m, b, r, p, se = stats.linregress(x=y_std, y=y_std_lag)\n",
    "print('m={:.4f}, b={:.4f}, r^2={:.4f}, p={:.4f}'.format(m, b, r ** 2, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the slope is the same as moran's I\n",
    "mi.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. LISAs\n",
    "\n",
    "Local Indicators of Spatial Autocorrelation: are there specific areas with high concentrations of (dis)similar values?\n",
    "\n",
    "Moran's I tells us about spatial clustering across the data set as a whole. However, it does not tell us where these clusters occur. For that, we need a local measure. Essentially, we will classify the data set's observations into four groups based on the four quadrants of the Moran plot:\n",
    "\n",
    "  1. HH: high value near other high values (hot spots)\n",
    "  1. LL: low value near other low values (cold spots)\n",
    "  1. HL: high value near low values (spatial outliers)\n",
    "  1. LH: low value near high values (spatial outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized moran's plot again, from subsection above\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "ax.text(1.25, 1.25, 'HH', fontsize=20)\n",
    "ax.text(1.25, -1.75, 'HL', fontsize=20)\n",
    "ax.text(-1.75, 1.25, 'LH', fontsize=20)\n",
    "ax.text(-1.75, -1.75, 'LL', fontsize=20)\n",
    "sns.regplot(ax=ax, x=y_std, y=y_std_lag, scatter_kws={'s':1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa = ps.explore.esda.Moran_Local(data_lag[col], w_queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the significance threshold\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify whether each observation is significant or not\n",
    "# p-value interpretation same as earlier with moran's I\n",
    "data_lag['significant'] = lisa.p_sim < alpha\n",
    "data_lag['significant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the quadrant each observation belongs to\n",
    "data_lag['quadrant'] = lisa.q\n",
    "data_lag['quadrant'] = data_lag['quadrant'].replace({1:'HH', 2:'LH', 3:'LL', 4:'HL'})\n",
    "data_lag['quadrant'].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the original tracts and LISA quadrants data together\n",
    "tracts_lisa = gpd.GeoDataFrame(pd.merge(tracts, data_lag, how='left', left_index=True, right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis then draw the basemap of tracts\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "tracts_lisa.plot(ax=ax, facecolor='#999999', edgecolor='k', linewidth=0.2)\n",
    "\n",
    "# plot each quandrant's tracts (if significant LISA statistic) in a different color\n",
    "quadrant_colors = {'HH':'r', 'LL':'b', 'LH':'skyblue', 'HL':'pink'}\n",
    "for q, c in quadrant_colors.items():\n",
    "    mask = tracts_lisa['significant'] & (tracts_lisa['quadrant'] == q)\n",
    "    rows = tracts_lisa.loc[mask]\n",
    "    rows.plot(ax=ax, color=c, edgecolor='k', linewidth=0.2)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In red we see clusters of tracts with high values surrounded by other high values. In blue we see clusters of tracts with low values surrounded by other low values. In pink, we see the first type of spatial outliers: tracts with high values but surrounded by low values. Finally, in light blue we see the other type of spatial outlier: tracts with low values surrounded by other tracts with high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
